load iris_data.mat[N, d] = size(data);global k;k = 3;  % Number of classes%%%% Helper Functions% Given r and j, this computes |Cj|function y = clusterSize(r, j)  y = sum(r(:, j) == 1);end% E step (calculating means)function newMu = updateMu(data, r)  global k;  [N, d] = size(data);    newMu = zeros(1, d);  for i = 1:k    currentSum = zeros(1, d);    for j = 1:N      if (r(j, i) == 1)        currentSum = currentSum + data(j, :);      end    end    cSize = clusterSize(r, i);    newMu(i, :) = currentSum / (cSize + (cSize == 0) * eps); % Avoid division by 0  endend% M step (updating r)function newR = updateR(data, mu, r)  global k;  [N, d] = size(data);    newR = r;  % min always takes the first occurance of the minimum,  % so we don't have to worry about infinite loops  for i = 1:N    norms = zeros(k, 1);    for j = 1:k      norms(j) = norm(data(i, :) - mu(j, :));    end    [M, I] = min(norms);    newR(i, :) = zeros(1, k);    newR(i, I) = 1;  endend% Assign via random partition method (RPM)function [mu, r] = rpm(data)  global k;  [N, d] = size(data);    r = zeros(N, k); % The row is the data point, and the columns give its current classification  for i = 1:N    col = ceil(rand * k);    r(i, col) = 1;  end  mu = updateMu(data, r); % updateMu just calculates the means, essentiallyend% Assign via the Forgy methodfunction [mu, r] = forgy(data)  global k;  [N, d] = size(data);    r = zeros(N, k); % The row is the data point, and the columns give its current classification  p = randperm(N, k);  for i = 1:k    mu(i, :) = data(p(i), :);  endend  %%%% Main Script% Initialization[mu, r] = forgy(data);while true  newR = updateR(data, mu, r); % E step  mu = updateMu(data, newR);   % M step  if (r == newR) % Check if points were moved to a new cluster    break;  else    r = newR;  endendclassifications = zeros(N, 1);for i = 1:N  for j = 1:k    if (r(i, j) == 1)      classifications(i) = j;    end  endendmuclassifications