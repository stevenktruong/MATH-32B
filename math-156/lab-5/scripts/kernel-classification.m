load two_moons.mat[dim, dataSize] = size(data);global N C t k lambda;N = 100;              % Number of classes considered knownC = data(:, 1:N);     % Each column is an observationt = -2 * labels .+ 3; % Map 1 -> 1 and 2 -> -1k = 8;        % k-th nearest neighbor to uselambda = 0.1; % Arbitrary positive scalar%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Helper Functions%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Calculates the k-th nearest neighbor of x given the known datafunction [s, y] = kthNN(x)  global N C t k;  [classified, k, dist, index] = fastKNN([C', t(1:N)], x', k);    s = dist(k);  y = C(:, index(k));    % This happens if x is in C  if (dist(1) == 0)    s = dist(k + 1);    y = C(:, index(k + 1));  endend% Calculates K(x, y)%   sx and sy are scaling factorsfunction y = kernel(x, y, sx, sy)  y = exp(-norm(x - y)^2 / (sx * sy));end% Gives classification for x%   sx is the scaling factor for x%   Kinv is the inverse of K + lambda * I%   s contains scaling factors for everything%   t contains the classes of the datafunction y = kernelClassify(x, sx, Kinv, s, t)  global N C;  for i = 1:N    k(i) = kernel(x, C(:, i), sx, s(i));  end  y = k * Kinv * t;end%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Main Script%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Calculate sigmas for datafor i = 1:dataSize  s(i) = kthNN(data(:, i));end  % Calculate kernel matrixfor n = 1:N  for m = 1:N    K(n, m) = kernel(C(:, n), C(:, m), s(n), s(m));  endend% Calculate inverse of a matrix K + lambda * IKinv = inverse(K + eye(N) * lambda);% Calculate accuracyaccurate = 0;for i = (N+1):dataSize  if (sign(kernelClassify(data(:, i), s(i), Kinv, s, t(1:N))) == t(i))    accurate = accurate + 1;  endendaccurate / (dataSize - N)